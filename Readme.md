Compte rendu â€“ TP : Introduction Ã  la classification (Wine Quality)
ğŸ¯ Objectif

Lâ€™objectif de ce TP est d'apprendre un modÃ¨le prÃ©dictif permettant de dÃ©terminer la qualitÃ© dâ€™un vin blanc (bonne ou mauvaise) Ã  partir de caractÃ©ristiques physico-chimiques.
Le dataset provient de l'UCI Machine Learning Repository (Wine Quality).

1. ğŸ“Š Analyse des donnÃ©es
1.1 Chargement et rÃ©sumÃ© du dataset

Le jeu de donnÃ©es est chargÃ© depuis lâ€™URL fournie, puis rÃ©sumÃ© via pandas.
On obtient :

Nombre dâ€™Ã©chantillons : 4898

Nombre de variables dâ€™entrÃ©e : 11

Variable cible : quality

1.2 Variables dâ€™entrÃ©e (X) et sortie (Y)

X : ensemble des caractÃ©ristiques physico-chimiques

Y : qualitÃ© du vin (score 0â€“10)

RÃ©partition des qualitÃ©s : affichÃ©e via value_counts().

1.3 Transformation en classification binaire

Une nouvelle variable cible est crÃ©Ã©e :

mauvaise qualitÃ© (0) si qualitÃ© â‰¤ 5

bonne qualitÃ© (1) sinon

La distribution des deux classes est rÃ©Ã©quilibrÃ©e.

1.4 Analyse statistique

Une analyse descriptive est rÃ©alisÃ©e :

BoÃ®tes Ã  moustaches â†’ distribution, valeurs extrÃªmes

Matrice de corrÃ©lation â†’ redondance entre certaines variables (par ex. densitÃ© â†” sucre rÃ©siduel)

2. ğŸ¤– Classification
2.1 SÃ©paration du dataset

Les donnÃ©es sont scindÃ©es en trois ensembles :

EntraÃ®nement (Da)

Validation (Dv)

Test (Dt)

Avec stratification sur les classes pour conserver les proportions.
Pourquoi ?

Ã©viter un dÃ©sÃ©quilibre dans les classes

assurer une bonne reprÃ©sentativitÃ©

amÃ©liorer la gÃ©nÃ©ralisation

2.2 MÃ©thode des k plus proches voisins (k-NN)
2.2.1 PremiÃ¨re expÃ©rimentation : k = 3

EntraÃ®nement sur Da

PrÃ©diction sur Dv

Calcul de lâ€™erreur :

error rate
=
1
âˆ’
accuracy
error rate=1âˆ’accuracy
2.2.2 Ã‰tude des performances selon k

Pour plusieurs valeurs de k (1 Ã  40) :

Calcul de lâ€™erreur sur :

entraÃ®nement â†’ dÃ©tecte le sur-apprentissage

validation â†’ choix du meilleur compromis

Observation attendue :

k faible â†’ fort sur-apprentissage

k trop grand â†’ sur-lissage, perte de prÃ©cision

2.2.3 Choix optimal de k

Le meilleur k est celui minimisant l'erreur de validation.

ğ‘˜
âˆ—
=
arg
â¡
min
â¡
ğ‘˜
(
error
ğ‘£
ğ‘
ğ‘™
)
k
âˆ—
=arg
k
min
	â€‹

(error
val
	â€‹

)
2.2.4 Performance sur lâ€™ensemble test

On Ã©value lâ€™erreur finale avec le modÃ¨le utilisant 
ğ‘˜
âˆ—
k
âˆ—
.
Discussion : performance cohÃ©rente ou non, Ã©cart entre validation et test.

2.3 Normalisation des donnÃ©es
2.3.1 Pourquoi normaliser ?

k-NN est sensible :

aux diffÃ©rences d'Ã©chelle entre variables
â†’ une variable Ã  grande variance domine la distance euclidienne.

Le code applique :

sc = StandardScaler(with_mean=True, with_std=True)
sc = sc.fit(Xa)
Xa_n = sc.transform(Xa)
Xv_n = sc.transform(Xv)


Remarque :
La normalisation est apprise sur Da uniquement, ce qui Ã©vite une fuite dâ€™information.
â†’ Câ€™est la bonne pratique.

2.3.2 RÃ©pÃ©tition des expÃ©riences

Les performances sont recalculÃ©es avec donnÃ©es normalisÃ©es.

RÃ©sultat attendu :

amÃ©lioration significative des performances

meilleure stabilitÃ© pour la recherche de k

rÃ©duction du sur-apprentissage

2.3.3 Comment rendre les modÃ¨les moins sensibles au dÃ©coupage des donnÃ©es ?

utiliser la validation croisÃ©e (k-fold)

rÃ©pÃ©ter plusieurs splits alÃ©atoires

augmenter les donnÃ©es si possible

âœ” Conclusion

Ce TP a permis de :

manipuler un dataset rÃ©el et analyser ses caractÃ©ristiques

transformer un problÃ¨me multi-classe en binaire

mettre en Å“uvre le classifieur k-NN

comprendre lâ€™impact crucial :

du choix de k

de la normalisation

du dÃ©coupage stratifiÃ© des donnÃ©es

Le modÃ¨le k-NN, malgrÃ© sa simplicitÃ©, fournit de bons rÃ©sultats si les donnÃ©es sont correctement normalisÃ©es et que le choix de k est guidÃ© par la validation.
