Delivery Logistics Dataset – Rapport de L'analyse de Regression 

# Sanae Belyasmine - Etudiante Groupe 1 CAC


# 1. Introduction

Ce rapport présente une analyse complète du Delivery Logistics Dataset, réalisée à travers un workflow de régression linéaire.
L’objectif principal est d’identifier les facteurs qui influencent la variable cible (définie comme la dernière colonne numérique du dataset) et d’évaluer la performance du modèle prédictif.

L’analyse suit une séquence structurée :

Importation des bibliothèques

Chargement du dataset

Nettoyage et préparation

Analyse exploratoire (EDA)

Sélection des variables

Division Train/Test

Création du modèle de régression

Évaluation des performances

Visualisation

Synthèse finale

# 2. Importation des bibliothèques

Les librairies suivantes ont été utilisées :

pandas : gestion des données

numpy : opérations numériques

matplotlib / seaborn : visualisations

scikit-learn : modèle de régression + métriques

Ces outils constituent un environnement Python standard pour l’analyse prédictive.

# 3. Chargement du Delivery Logistics Dataset

Le dataset a été chargé via files.upload() dans Google Colab.
Les premières lignes (df.head()) montrent une structure tabulaire composée de variables :

numériques (quantitatives)

catégorielles (qualitatives)

logistiques (distances, durées, statuts, etc.)

La nature exacte dépend du contenu du fichier fourni.

# 4. Compréhension et nettoyage des données
✔️ Les étapes réalisées :

df.info() : inspection des types et des colonnes

df.describe() : statistiques descriptives

Détection de valeurs manquantes

Traitement des valeurs manquantes :

numérique → median

catégorielle → mode

Suppression des doublons

✔️ Résultat

Le dataset final ne contient plus de valeurs manquantes et ne comporte plus de doublons.
Il est désormais propre et prêt pour l’analyse.

# 5. Analyse Exploratoire (EDA)
✔️ Visualisations réalisées :
1. Histogrammes / distribution

Pour chaque variable numérique, un histogramme avec courbe KDE a été tracé.
Objectif : observer la dispersion, la forme et la variabilité.

2. Matrice de corrélation

Une heatmap a révélé :

les relations linéaires entre les variables

les facteurs fortement associés à la variable cible

les redondances entre variables explicatives

3. Pairplot (sélection limitée)

Permet de visualiser :

patterns globaux

tendances linéaires

clusters éventuels

# 6. Feature Selection (sélection des variables)
✔️ Définition :

La variable cible (Y) est définie comme la dernière variable numérique du dataset.

Les predictors (X) incluent toutes les autres colonnes.

✔️ Encoding

Les variables catégorielles sont converties en dummies (one-hot encoding).
Ce traitement garantit la compatibilité du dataset avec le modèle de régression.

# 7. Train/Test Split

Le dataset a été divisé comme suit :

80% → entraînement

20% → test

random_state=42 pour assurer une reproductibilité

Cette étape permet de valider le modèle sur des données non vues.

# 8. Modèle de régression linéaire
✔️ Entraînement

Un modèle LinearRegression() a été ajusté sur les données d’entraînement.

✔️ Paramètres extraits :

Intercept (b0)

Coefficients bi pour chaque Xi

✔️ Formule reconstituée :
Y = b0 + (b1 * X1) + (b2 * X2) + ... + (bn * Xn)


Cette formule décrit l’influence linéaire de chaque variable sur la cible.

# 9. Prédictions & Évaluation
✔️ Les métriques calculées :
Metric	Signification
R²	Qualité globale du modèle (variance expliquée)
MSE	Erreur quadratique moyenne
RMSE	Erreur moyenne en unités réelles
MAE	Erreur absolue moyenne
✔️ Interprétation générale :

R² proche de 1 → modèle performant

R² faible (<0.4) → modèle peu explicatif

MAE / RMSE faibles → bonne précision

Les valeurs exactes dépendent du dataset fourni.

# 10. Visualisation : Réel vs Prédit

Un graphique scatter présente :

les valeurs réelles en abscisse

les valeurs prédites en ordonnée

une ligne diagonale rouge représentant la prédiction parfaite

Plus les points sont proches de la ligne → meilleur est le modèle.

# 11. Synthèse finale
✔️ Variables les plus influentes

Une analyse des coefficients absolus a permis d’identifier les variables ayant le plus d’impact sur la variable cible.

Ces variables constituent les facteurs logistiques majeurs influençant le comportement mesuré (ex : délai de livraison, coût, performance, distance, temps de transport — selon ton dataset réel).

✔️ Conclusion générale du modèle

Le modèle de régression linéaire permet d’identifier clairement les relations linéaires entre les paramètres du Delivery Logistics Dataset.

La qualité du modèle dépend du R² obtenu.

Les coefficients permettent d’interpréter directement l’influence de chaque variable.

Un R² satisfaisant atteste que les variables explicatives sélectionnées jouent un rôle déterminant dans la prédiction.

# 12. Recommandations

Tester d’autres modèles : Ridge, Lasso, Random Forest Regressor

Normaliser les données si les échelles sont trop différentes

Ajouter ou supprimer des variables selon la corrélation

Évaluer la multicolinéarité (Variance Inflation Factor)

Compléter l’analyse avec une optimisation d’hyperparamètres
